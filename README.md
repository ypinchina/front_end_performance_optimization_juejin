# 掘金小册——前端性能优化与实践

本项目将是掘金小册—— 前端性能优化与实践 的学习，本文件将记录学习笔记
## 知识体系： 从一道面试题说起

### 在展开性能优化的话题之前，我想先抛出一个老生常谈的面试问题：

* 从输入 URL 到页面加载完成，发生了什么？

    
我们将这个过程切分为如下的过程片段：

1. DNS 解析
2. TCP 连接
3. HTTP 请求抛出
4. 服务端处理请求，HTTP 响应返回
5. 浏览器拿到响应数据，解析响应内容，把解析的结果展示给用户
大家谨记，我们任何一个用户端的产品，都需要把这 5 个过程滴水不漏地考虑到自己的性能优化方案内、
反复权衡，从而打磨出用户满意的速度。

## 网络篇
1. webpack性能调优与Gzip

首先 ，根据引言的问题 ，我们先做网络部分的优化， 其中DNS和TCP连接前端无法改变太多，因此
我们主要从HTTP优化入手。
HTTP的优化主要分为两个部分
* 减少请求次数
* 减少单次请求所花费的时间

这两个优化无疑是指向我们日常开发的常见操作—— **资源的合并与压缩**
我们通常都是使用构建工具来实现这些需求，而业界巨无霸的构建工具无疑是webpack

### webpack的性能瓶颈

对于资源的压缩与合并，是老生常谈的问题，建议查看文档。
这里主要讲的是优化webpack,webpack性能调优的方向主要有两个：

1. webpack构建时间太长
2. webpack打包太大

### 构建过程提速策略

1. 不要让loader做过多的事情

babel-loader显然是强大的，但也是慢的
常见的优化方式是使用include和exclude进行文件范围限定。
刨除node_modules文件夹和bower_components，以下是官方文档的例子

```javascript
module: {
  rules: [
    {
      test: /\.js$/,
      exclude: /(node_modules|bower_components)/,
      use: {
        loader: 'babel-loader',
        options: {
          presets: ['@babel/preset-env']
        }
      }
    }
  ]
}
```
### 缓存之前构建过的js
使用文件夹限定的优化提升是有限的，所以我们还可以开启缓存将转译的结果
保存到文件系统，则至少可以将 babel-loader 的工作效率提升两倍。只需要
增加参数即可

将Babel编译过的文件缓存起来，下次只需要编译更改过的代码文件即可，这样可以大幅度加快打包时间。

`loader: 'babel-loader?cacheDirectory=true'`

讲完了loader，还需要放眼于plugins。
### 不要放过第三方库
每次构建的时候，一些第三方库都会重新编译，但是他们短时间内不会有变化，庞大的第三方库
的编译会极大消耗时间。

最好的方案是使用dllPlugin,这个插件会把第三方库单独打包到一个文件中，
这个文件就是一个单纯的依赖库。这个依赖库不会跟着你的业务代码一起被重新打包，
只有当依赖自身发生版本变化时才会重新打包。

使用dllPlugin处理文件分两步走
1. 基于 dll 专属的配置文件，打包 dll 库
2. 基于 webpack.config.js 文件，打包业务代码

然后，根据编写dll处理文件（此处理文件代码看文档），使用dllPlugin,
会生成两个文件
* vendor.js
* vendor-manifest.js

其中vendor.js是第三方库文件，而vendor-manifest.js则是则用于描述
每个第三方库对应的具体路径

然后只需要在webpack.config.js文件中配置dllPlugin的manifest关联到vendor.js即可
完成本次dllPlugin的优化（此处参考文档）

### 使用Happypack——将 loader 由单进程转为多进程

受限于 Node 是单线程运行的webpack 是单线程的，就算此刻存在多个任务，你也只能排队一个接一个地等待处理，
所以 Webpack 在打包的过程中也是单线程的，特别是在执行 Loader 的时候，
长时间编译的任务很多，这样就会导致等待的情况。HappyPack和ThreadLoader作用是一样的，
都是同时执行多个进程，从而加快构建速度。而Thread-Loader是webpack4官方提出的，而HappyPack作者已经
很久没维护了。

采用HappyPack开启多进程Loader

虽然webpack是单线程，但好在用户是多核电脑，Happypack 会充分释放 CPU 在多核并发方面的优势，
帮我们把任务分解给多个子进程去并发执行，大大提升打包效率。

这两种工具配置请参考文档，原理是把loader 的配置转移到 HappyPack 中去就好，
我们可以手动告诉 HappyPack 我们需要多少个并发的进程

需要注意的是，开启多进程的意义在于需要构建的文件的体积足够大，如果不够大，
不然效果不够明显，明显有高射炮打小苍蝇的感觉。因为进程开启需要时间，
进程之间的通信也需要时间，如果这点时间都不能忽略不计，那么意义不大。（太小会反而增加构建用时）

### 删除冗余代码
从webpack2开始，webpack开始支持es6自带的es module语法， 因此开始引入支持Tree-shaking
Tree-shaking原理就是基于 import/export来优化剪掉多余的代码。webpack5中mode为production
时默认开启Tree-shaking

* Tree-shaking显然是针对模块化大型代码裁剪比较给力。而精细程度的代码优化裁剪，
使用UglifyJsPlugin，可以优化删除console.log,和注释

### 按需加载
* 异步路由
原理是路由分包按需加载，Vue中使用import或者require来实现,如：
`const Editor = () => import('@/views/Editor') `

## Gzip压缩原理

具体的做法非常简单，只需要你在你的 request headers 中加上这么一句：

accept-encoding:gzip


Gzip 压缩背后的原理，是在一个文本文件中找出一些重复出现的字符串、临时替换它们，
从而使整个文件变小。根据这个原理，文件中代码的重复率越高，那么压缩的效率就越高，
使用 Gzip 的收益也就越大。反之亦然。
## 图片———— 性能与质量平衡点的博弈

前言
《高性能网站建设指南》的作者 Steve Souders 曾在 2013 年的一篇 博客 中提到：
曾经他以为性能优化的大头在于CSS与JS，后来他意识到自己错了，真正的大头在于网络图片

## 图片的性能优化需要在图片压缩性能和图片质量之间找到一个合理的平衡点

### 前置知识
二进制位数与色彩的关系：在计算机中，像素用二进制数来表示。不同的**图片格式**中像素与二进制位数之间的对应关系是不同的。一个像素对应的二进制位数越多，
它可以表示的颜色种类就越多，成像效果也就越细腻，文件体积相应也会越大。

1. jpg/jpeg
特点： **有损压缩，体积小，加载快，不支持透明**
jpg是色彩丰富的图片，即使有损压缩，也能保证图片的质量。jpg即使被压缩了50%,也能保证有60%以上的图片质量。jpg以24位二进制存储单个图，能呈现1600万中色彩
一般用于背景图和轮播图以及banner大图
缺陷： 不支持透明， 不善于处理LOGO和矢量图等线条感丰富的图片

2. png-8, png-24
特点： **无损压缩，质量高，体积大，支持透明**

-8可呈现256种色彩，而-24约1600万种色彩，png什么都好，唯一的BUG就是太大了。需要权衡何时用-8，何时用-24

应用场景： 对于多色彩鲜艳的大图片，一般是使用.jpg来呈现，因为若是使用.png，那实在是太大了，而png一般用于在较小、色彩简单或透明的logo小图。

3. svg
关键字 **文本文件、体积小、不失真，兼容性好**

* 文本文件 —— 可嵌入html文件里，作为DOM的一部分。 

SVG的缺点（局限性）： 1. 渲染成本高，对于性能来说很不利； 2. 有其他图片格式所没有的学习成本（可编程）

4. Base64与雪碧图（图像精灵）
两者都是用于解决小图标的解决方案: 
雪碧图是将多个小图标拼接在一张图片中，以减少http请求次数。
Base64是作为雪碧图的**补充**而存在的
Base64不是图片格式，而是一种编码方式。将图片编译成字符串存放在html文件或者css文件中减少这张图片的请求次数。但是并非所有图片都适用于这种编码方式。因为使用该编码会使图片的大小
膨胀为原文件的4/3（这是由 Base64 的编码原理决定的）。所以过大的图片会膨胀会使css文件或者HTML文件文件体积显著增大，即使减少了http请求次数，也无法弥补体积膨胀带来的性能开销，得不偿失。

一张图片使用Base64的场景
1. 小图，图片尺寸很小
2. 图片更新频率非常低（不需我们重复编码和修改文件内容，维护成本较低）

* Base64编码转换工具
** 最推荐的还是webpack的url-loader（全自动编译 + 用户设置图片尺寸转换阈值）
** 在线网页工具

5. WebP 年轻的全能型选手
